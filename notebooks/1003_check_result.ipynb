{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a01347-6d1d-4e44-a6dc-8015ba8ab827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7e7091-7276-43e9-86c2-bb068fe1ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model import TSFashionNet\n",
    "from dataset import TSDataset\n",
    "from utils import add_weight_heatmap, landmark_check, visibility_check, category_check, attribute_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba687472-12c2-4385-994e-bcbe86b48d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9bed5f-da5a-4da9-9873-ef5ae816bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSFashionNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ec9c68-0871-49ef-ac5e-3a64423f1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dict = torch.load('/media/jaeho/HDD/ckpt/TSFashionNet/TSFashionNet_221003-0111/checkpoint-006-16.569.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a452d4-84dc-4943-a188-d1032e5a283f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d840979-1c84-4241-aad3-a24dbddf2de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15eb319-f6df-4339-80ed-3302284f05e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSFashionNet(\n",
       "  (texture_backbone): VggBackbone(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (texture_stream): Sequential(\n",
       "    (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): Conv2d(2048, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (clothes_cls_fc): Linear(in_features=4096, out_features=48, bias=True)\n",
       "  (attr_recog_fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  (shape_backbone): VggBackbone(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv5_maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (shape_stream): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (vis_fc): Linear(in_features=256, out_features=8, bias=True)\n",
       "  (location): Sequential(\n",
       "    (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35cbc5f0-673e-4428-9800-eafd4e6c38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TSDataset('/media/jaeho/SSD/datasets/deepfashion/split/test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1cb27b-1fad-47aa-a8ce-61d3382b7b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_idx = np.random.randint(len(test_dataset))\n",
    "target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d340b95-723a-46c0-a15d-44270c4ed7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d0a9d4-72a4-42b0-a92d-5da93629c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ea2b6e-2005-469c-bd4c-adc41a434242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t_n in range(try_num):\n",
    "    print(f\"{t_n+1} / {try_num}\")\n",
    "    target_idx = np.random.randint(len(test_dataset))\n",
    "    print(target_idx)\n",
    "    img, category, attribute, visibility, landmark = test_dataset[target_idx]\n",
    "    height, width = img.size\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    img_tensor = trans(img).to(device)\n",
    "    img_tensor = torch.unsqueeze(img_tensor, axis=0)\n",
    "    vis_out, lm_out, category_out, attr_out = model(img_tensor, shape=False)\n",
    "    \n",
    "    \n",
    "    ############## check landmark\n",
    "    # down_size\n",
    "    # resized_img = img.resize((14, 14))\n",
    "    # pred_lm = add_weight_heatmap(resized_img, lm_out.detach().cpu().squeeze().numpy(), plot=False)\n",
    "    # break\n",
    "    \n",
    "    landmark_check(img, lm_out, landmark)\n",
    "    ##################################\n",
    "    \n",
    "    #### category\n",
    "    category_check(category, category_out)\n",
    "    \n",
    "    #### attribute\n",
    "    attr_gt, attr_pred, attr_cor = attribute_check(attribute, attr_out, thr=0.3)\n",
    "    print()\n",
    "    print(attr_gt)\n",
    "    print(attr_pred)\n",
    "    print(attr_cor)\n",
    "    \n",
    "    #### visibility\n",
    "    vis_gt, vis_pred, vis_cor = visibility_check(visibility, vis_out)\n",
    "    print()\n",
    "    print(vis_gt)\n",
    "    print(vis_pred)\n",
    "    print(vis_cor)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############### break\n",
    "    input_str = input()\n",
    "    if input_str == \"\":\n",
    "        clear_output()\n",
    "    else :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b1f54-3689-41fc-9d8a-62a1fb4d33ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88fdd69e-1c4f-44c0-b6fc-833fd5b232d6",
   "metadata": {},
   "source": [
    "## to do\n",
    "1. attribute 전처리 값 확인\n",
    "    - gt자체도 아무런 값이 안들어갈 경우가 존재\n",
    "    - unknown? 그러한 라벨도 존재했었는데 일괄적으로 다 0으로 처리하고 명확한 정보에 대해서만 1이라고 전처리를 했었는데 이 부분을 변경해서도 준비해봐야 할 것 같음\n",
    "2. landmark 학습 디버깅\n",
    "    - loss는 분명 뭔가 줄어드는 걸로 보였는데, 실제로 결과를 확인해보면 처참\n",
    "    - visibility가 분명 loss 계산시에 같이 들어가기는 하는데..\n",
    "    - 그리고 gt값을 무지성으로 사이즈를 줄여서 pred와 비교를 하는데 여기서 pred를 키워본다면? --> 이건 논문 좀더 찾아보자\n",
    "    - 문제점 예상\n",
    "        1. loss 설계 문제?\n",
    "        2. pred값 upsize? (gt값 downsize?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a619e0-d935-47a2-86cc-cd3c9b0543ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(attr_out>=0.3, 1, 0).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f704201-7fc7-469e-a18c-2137e71b0f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[121],\n",
       "        [720],\n",
       "        [994]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5081e-3c71-4f70-967b-85620fa3d92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70ab395-b553-493e-90dc-b6e6c927e7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[836, 470, 568]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_pred = {idx:value for idx, value in enumerate(attr_out.detach().cpu().numpy())}\n",
    "attr_pred = dict(sorted(attr_pred.items(), reverse=True, key=lambda x: x[1]))\n",
    "list(attr_pred.keys())[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e5904-12be-4133-8a25-a915f1ec3e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
